<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Latent Textual Space: Pivot for Scaling Customized Text-to-Image and Video Generation</title>
  <link rel="icon" type="image/x-icon" href="static/images/WIS.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Latent Textual Space: Pivot for Scaling Customized Text-to-Image and Video Generation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">Jian Jin, Zhenbo Yu, Yang Shen, Zhenyong Fu, Jian Yang</span>
                </div>
            
                  <div class="is-size-6 publication-authors">
                    <span class="author-block"> </span>
                  </div>

                  <div class="is-size-4 publication-authors">
                    <span class="author-block">CVPR 2025 Highlight</span>

                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href='https://arxiv.org/pdf/2503.06956' target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jinjianRick/latexblend" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  
<!-- Teaser Section with Image and Title -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Insert Image -->
      <img src="pics/teaser.png" alt="Teaser Image" width="1200px">
      <!-- Insert Title -->
      <h2 class="subtitle has-text-left" style="font-size: 13px;">
        LatexBlend simultaneously addresses two key challenges in scaling multi-concept generation: ensuring high generation quality
        (including concept fidelity and layout coherence) and maintaining computational efficiency.
      </h2>
    </div>
  </div> 
</section>
<!-- End teaser section with image and title -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Customized generation renders user-specified concepts into novel contexts based on textual prompts.
            Scaling the number of concepts in customized generation meets a broader demand for user creation, whereas existing methods face challenges with generation quality and computational efficiency.
            In this paper, we introduce a novel Latent Textual Space (LTS), which follows the text encoder and a linear projection.
            We identify that LTS is the pivot in text-conditional diffusion models, offering three key merits for scaling customized generation: 1) sufficient customized information, 2) effective mitigation of denoising deviation, and 3) excellent scalability.
            We devise a customization framework to embed each individual concept into compact features in LTS, serving as a general concept representation for customized generation.
            Based on the introduced LTS, we develop LaTexBlend-I/G/V inference pipelines for three prominent customized generation tasks, enabling seamless plug-and-play combination of multiple concepts in customized text-to-image (T2I), grounded T2I, and text-to-video generation.
            These pipelines are built upon the core idea of Blend multiple general concept representations in the Latent Textual Space, with dedicated designs to address the unique challenges specific to each task.
            Extensive experiments demonstrate that our method effectively addresses key challenges in scaling multi-concept customized generation, significantly outperforming baselines in both generation quality and computational efficiency.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper poster -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">

            <!-- Subsection 1 -->
            <h3 class="title is-4 has-text-centered">Single-concept Customization</h3>
            <p>
            </p>
            <figure style="text-align: center;">
              <img src="pics/fine_tuning_framework.png" alt="Concept Representation" width="800" />
              <figcaption style="font-size: 13px;">Fine-tuning framework of the proposed LaTexBlend.  
                 LaTexBlend customizes each concept individually and stores it in a concept bank with compact latent textual features in LTS, serving as a 
                general concept representation for versatile customized generation tasks.</figcaption>
            </figure>

            <!-- Subsection 2 -->
            <h3 class="title is-4 has-text-centered">Customized T2I Generation</h3>
            <p>
              The latent textual space, positioned after the text encoder and a linear projection, serves as an efficient fusion layer for multiple concepts.
              It avoids early interference while retaining concept-specific features.
            </p>
            <figure style="text-align: center;">
              <img src="pics/t2i_pipeline.png" alt="Latent Textual Space" width="800" />
              <figcaption style="font-size: 13px;">Structure of the latent textual space for customized concept fusion.</figcaption>
            </figure>

            <!-- Subsection 3 -->
            <h3 class="title is-4 has-text-centered">Customized Grounded T2I Generation</h3>
            <p>
              During inference, multiple customized concepts can be dynamically blended within the latent textual space, enabling flexible multi-concept generation without additional fine-tuning.
            </p>
            <figure style="text-align: center;">
              <img src="pics/gt2i_pipeline.png" alt="Concept Blending" width="800" />
              <figcaption style="font-size: 13px;">On-the-fly blending of multiple concepts at inference time.</figcaption>
            </figure>

            <!-- Subsection 4 -->
            <h3 class="title is-4 has-text-centered">Customized T2V Generation</h3>
            <p>
              The fused representation is passed through the diffusion model to generate high-fidelity, layout-consistent images containing all customized concepts.
            </p>
            <figure style="text-align: center;">
              <img src="pics/t2v_pipeline.png" alt="Final Generation" width="800" />
              <figcaption style="font-size: 13px;">Output results demonstrating fidelity and coherence of generated images.</figcaption>
            </figure>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper poster -->
            
<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Comparisons</h2>
          <div class="content has-text-justified">
            <td colspan="3">
              <p style="margin-top: -12px;">
              </p>
            </td>
  <!-- </td> -->
          <tr>
            <td colspan="3" style="text-align: center; padding-bottom: 30px;">
              <img src="pics/comp1.png" alt="" width="1000" />
              <h2 class="subtitle has-text-center" style="font-size: 15px; text-align: center;">
                Visual Comparisons.
              </h2>
            </td>
          </tr>
          
          <tr>
            <td colspan="3" style="text-align: center; padding-bottom: 30px;">
              <!-- Ensure image is centered with display block and margin auto -->
              <img src="pics/comp2.png" alt="" width="1000" style="display: block; margin: 0 auto;" />
              <!-- Ensure title is centered -->
              <h2 class="subtitle has-text-center" style="font-size: 15px; text-align: center;">
                Visual comparison of generations with additional layout conditioning.
              </h2>
            </td>
          </tr>
            

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{jin2025latexblend,
        title={LatexBlend: Scaling Multi-concept Customized Generation with Latent Textual Blending},
        author={Jin, Jian and Zhenbo, Yu and Yang, Shen and Fu, Zhenyong and Yang, Jian},
        booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column custom-width">
          <!-- <h2 class="title is-3"></h2> -->
          <div class="content has-text-justified">
  <p>
    <a name="ref-ebsynth" id="ref-ebsynth"></a>
    <!-- [6] Gwanghyun Kim, Taesung Kwon, and Jong Chul Ye. Diffusionclip: Text-guided diffusion models for robust image manipulation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. -->
  </p>
  </div>
        </div>
      </div>
    </div>  
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
    <script>
      window.addEventListener('DOMContentLoaded', (event) => {
        const videoWrappers = document.querySelectorAll('.video-wrapper');
      
        videoWrappers.forEach(wrapper => {
          const defaultVideo = wrapper.querySelector('.default-video');
          const aspectRatio = defaultVideo.videoWidth / defaultVideo.videoHeight;
          const height = wrapper.offsetWidth / aspectRatio;
      
          wrapper.style.height = `${height}px`;
      
          wrapper.addEventListener('mouseenter', () => {
            defaultVideo.pause();
            hoverVideo.play();
          });
      
          wrapper.addEventListener('mouseleave', () => {
            defaultVideo.play();
            hoverVideo.pause();
          });
        });
      }); 
      $(document).ready(function() {
        var carouselItems = $('.carousel .item');
        var numItems = carouselItems.length;
        var numVideos = 5;
        var currentIndex = 0;
    
        $('.carousel').on('click', function() {
          currentIndex++;
          if (currentIndex + numVideos <= numItems) {
            carouselItems.removeClass('active');
            carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
          } else {
            currentIndex = 0;
            carouselItems.removeClass('active');
            carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
          }
        });
    
        carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
      });
    </script>
  </body>
  </html>
